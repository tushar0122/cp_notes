Every DP solution involves a "state" â€” even simple ones like dp[i] â€” because DP is about storing subproblem results.

But a state machine approach is used when:
    => States represent modes or conditions that change (on/off, holding/not holding).
    => Transitions depend on these modes.

Many classic DP problems donâ€™t need state machine modeling because:
    => Thereâ€™s a simple recurrence relation.
    => You donâ€™t have to track multiple â€œstatesâ€, just one dimension or two.

Youâ€™ll see state machines when:
    => You have multiple decisions at each step (e.g., buy/sell, match/skip).
    => You have to track status/history across time or positions.
    => You have constraints like cooldowns, limits, or dependencies.

ðŸ”„ Examples:
    => Stock Buy/Sell with cooldown or limits â†’ Track holding/selling/resting
    => DP on strings (e.g., regular expression matching) â†’ Track pattern vs string states
    => Task scheduling with dependencies â†’ Track time, task state
    => DP on graphs with cost/state â†’ E.g., Traveling Salesman Problem with visited mask